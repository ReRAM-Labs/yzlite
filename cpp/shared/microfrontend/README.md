# Microfrontend

This is based on the library provided by Google: [Microfrontend](https://github.com/tensorflow/tflite-micro/tree/main/tensorflow/lite/experimental/microfrontend)

It converts streaming audio into a spectrogram.

## Also see

- [AudioFeatureGenerator ReRAM Engine  documentation](https://docs.yizhu.com/reram-platform/latest/machine-learning/api/group-ml-audio-feature-generation)
- [AudioFeatureGenerator YZLITE documentation](https://github.com/ReRAM-Labs/yzlite/docs/audio/audio_feature_generator.html)
- [AudioFeatureGenerator Python Wrapper documentation](https://github.com/ReRAM-Labs/yzlite/docs/cpp_development/wrappers/audio_feature_generator_wrapper.html)
